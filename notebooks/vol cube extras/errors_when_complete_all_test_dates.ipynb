{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download, normalize and split vol cube data into train/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')  # to go to the main folder of the whole project\n",
    "\n",
    "from src.data.vol.get_vol_cube_tenors_strikes_dates import get_vol_cube_tenors_strikes_dates\n",
    "data, uniq_opt_tenors, uniq_swap_tenors, uniq_strikes, dates = get_vol_cube_tenors_strikes_dates()\n",
    "\n",
    "# Normalize data\n",
    "from src.data.vol.normalizer import Normalizer\n",
    "normalizer = Normalizer()\n",
    "data_norm = normalizer.normalize(data)\n",
    "\n",
    "# Split train and test datasets\n",
    "seed = 0 # other seeds provides the same result\n",
    "from src.utils.get_train_test_datasets import get_train_test_datasets\n",
    "data_norm_train, dates_train, data_norm_test, dates_test = get_train_test_datasets(data_norm,\n",
    "                                                                                   dates,\n",
    "                                                                                   seed=seed,\n",
    "                                                                                   train_ratio=0.8)\n",
    "\n",
    "data_train = normalizer.denormalize(data_norm_train)\n",
    "data_test = normalizer.denormalize(data_norm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the saved model and its history from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\alexi\\Documents\\All\\ETH_UZH\\MasterThesis\\_MT_Vol_cube\\code_my\\autoencoder_library\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:192: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexi\\Documents\\All\\ETH_UZH\\MasterThesis\\_MT_Vol_cube\\code_my\\autoencoder_library\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 46 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from src.utils.load_model_and_history import load_model_and_history\n",
    "\n",
    "NAME = 'vol_cube_vae_van_2latd_400_200_200_100_3000ep_bat16_2e-06_seed0'\n",
    "vae, history = load_model_and_history(NAME,\n",
    "                                      data_type='vol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's select that ATM vols will be missed for the date with largest vols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create dataset with missed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset data_norm_test_missed with missed data\n",
    "import numpy as np\n",
    "missed_strike = 3  # 0 is ATM-100bp, 3 is ATM, 6 is ATM+100bp\n",
    "\n",
    "# Import what value is considered as a missed value\n",
    "from references.global_parameters import MISSED_VALUE\n",
    "\n",
    "from src.visualization.vol.find_z_to_complete_vol_cube import find_z_to_complete_vol_cube\n",
    "strikes = ['ATM-100bp', 'ATM-50bp', 'ATM', 'ATM+50bp', 'ATM+100bp']  # graphs only for these strikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate mse error over all test dates when we complete the dataset (takes 6 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 266\n",
      "1 out of 266\n",
      "2 out of 266\n",
      "3 out of 266\n",
      "4 out of 266\n",
      "5 out of 266\n",
      "6 out of 266\n",
      "7 out of 266\n",
      "8 out of 266\n",
      "9 out of 266\n",
      "10 out of 266\n",
      "11 out of 266\n",
      "12 out of 266\n",
      "13 out of 266\n",
      "14 out of 266\n",
      "15 out of 266\n",
      "16 out of 266\n",
      "17 out of 266\n",
      "18 out of 266\n",
      "19 out of 266\n",
      "20 out of 266\n",
      "21 out of 266\n",
      "22 out of 266\n",
      "23 out of 266\n",
      "24 out of 266\n",
      "25 out of 266\n",
      "26 out of 266\n",
      "27 out of 266\n",
      "28 out of 266\n",
      "29 out of 266\n",
      "30 out of 266\n",
      "31 out of 266\n",
      "32 out of 266\n",
      "33 out of 266\n",
      "34 out of 266\n",
      "35 out of 266\n",
      "36 out of 266\n",
      "37 out of 266\n",
      "38 out of 266\n",
      "39 out of 266\n",
      "40 out of 266\n",
      "41 out of 266\n",
      "42 out of 266\n",
      "43 out of 266\n",
      "44 out of 266\n",
      "45 out of 266\n",
      "46 out of 266\n",
      "47 out of 266\n",
      "48 out of 266\n",
      "49 out of 266\n",
      "50 out of 266\n",
      "51 out of 266\n",
      "52 out of 266\n",
      "53 out of 266\n",
      "54 out of 266\n",
      "55 out of 266\n",
      "56 out of 266\n",
      "57 out of 266\n",
      "58 out of 266\n",
      "59 out of 266\n",
      "60 out of 266\n",
      "61 out of 266\n",
      "62 out of 266\n",
      "63 out of 266\n",
      "64 out of 266\n",
      "65 out of 266\n",
      "66 out of 266\n",
      "67 out of 266\n",
      "68 out of 266\n",
      "69 out of 266\n",
      "70 out of 266\n",
      "71 out of 266\n",
      "72 out of 266\n",
      "73 out of 266\n",
      "74 out of 266\n",
      "75 out of 266\n",
      "76 out of 266\n",
      "77 out of 266\n",
      "78 out of 266\n",
      "79 out of 266\n",
      "80 out of 266\n",
      "81 out of 266\n",
      "82 out of 266\n",
      "83 out of 266\n",
      "84 out of 266\n",
      "85 out of 266\n",
      "86 out of 266\n",
      "87 out of 266\n",
      "88 out of 266\n",
      "89 out of 266\n",
      "90 out of 266\n",
      "91 out of 266\n",
      "92 out of 266\n",
      "93 out of 266\n",
      "94 out of 266\n",
      "95 out of 266\n",
      "96 out of 266\n",
      "97 out of 266\n",
      "98 out of 266\n",
      "99 out of 266\n",
      "100 out of 266\n",
      "101 out of 266\n",
      "102 out of 266\n",
      "103 out of 266\n",
      "104 out of 266\n",
      "105 out of 266\n",
      "106 out of 266\n",
      "107 out of 266\n",
      "108 out of 266\n",
      "109 out of 266\n",
      "110 out of 266\n",
      "111 out of 266\n",
      "112 out of 266\n",
      "113 out of 266\n",
      "114 out of 266\n",
      "115 out of 266\n",
      "116 out of 266\n",
      "117 out of 266\n",
      "118 out of 266\n",
      "119 out of 266\n",
      "120 out of 266\n",
      "121 out of 266\n",
      "122 out of 266\n",
      "123 out of 266\n",
      "124 out of 266\n",
      "125 out of 266\n",
      "126 out of 266\n",
      "127 out of 266\n",
      "128 out of 266\n",
      "129 out of 266\n",
      "130 out of 266\n",
      "131 out of 266\n",
      "132 out of 266\n",
      "133 out of 266\n",
      "134 out of 266\n",
      "135 out of 266\n",
      "136 out of 266\n",
      "137 out of 266\n",
      "138 out of 266\n",
      "139 out of 266\n",
      "140 out of 266\n",
      "141 out of 266\n",
      "142 out of 266\n",
      "143 out of 266\n",
      "144 out of 266\n",
      "145 out of 266\n",
      "146 out of 266\n",
      "147 out of 266\n",
      "148 out of 266\n",
      "149 out of 266\n",
      "150 out of 266\n",
      "151 out of 266\n",
      "152 out of 266\n",
      "153 out of 266\n",
      "154 out of 266\n",
      "155 out of 266\n",
      "156 out of 266\n",
      "157 out of 266\n",
      "158 out of 266\n",
      "159 out of 266\n",
      "160 out of 266\n",
      "161 out of 266\n",
      "162 out of 266\n",
      "163 out of 266\n",
      "164 out of 266\n",
      "165 out of 266\n",
      "166 out of 266\n",
      "167 out of 266\n",
      "168 out of 266\n",
      "169 out of 266\n",
      "170 out of 266\n",
      "171 out of 266\n",
      "172 out of 266\n",
      "173 out of 266\n",
      "174 out of 266\n",
      "175 out of 266\n",
      "176 out of 266\n",
      "177 out of 266\n",
      "178 out of 266\n",
      "179 out of 266\n",
      "180 out of 266\n",
      "181 out of 266\n",
      "182 out of 266\n",
      "183 out of 266\n",
      "184 out of 266\n",
      "185 out of 266\n",
      "186 out of 266\n",
      "187 out of 266\n",
      "188 out of 266\n",
      "189 out of 266\n",
      "190 out of 266\n",
      "191 out of 266\n",
      "192 out of 266\n",
      "193 out of 266\n",
      "194 out of 266\n",
      "195 out of 266\n",
      "196 out of 266\n",
      "197 out of 266\n",
      "198 out of 266\n",
      "199 out of 266\n",
      "200 out of 266\n",
      "201 out of 266\n",
      "202 out of 266\n",
      "203 out of 266\n",
      "204 out of 266\n",
      "205 out of 266\n",
      "206 out of 266\n",
      "207 out of 266\n",
      "208 out of 266\n",
      "209 out of 266\n",
      "210 out of 266\n",
      "211 out of 266\n",
      "212 out of 266\n",
      "213 out of 266\n",
      "214 out of 266\n",
      "215 out of 266\n",
      "216 out of 266\n",
      "217 out of 266\n",
      "218 out of 266\n",
      "219 out of 266\n",
      "220 out of 266\n",
      "221 out of 266\n",
      "222 out of 266\n",
      "223 out of 266\n",
      "224 out of 266\n",
      "225 out of 266\n",
      "226 out of 266\n",
      "227 out of 266\n",
      "228 out of 266\n",
      "229 out of 266\n",
      "230 out of 266\n",
      "231 out of 266\n",
      "232 out of 266\n",
      "233 out of 266\n",
      "234 out of 266\n",
      "235 out of 266\n",
      "236 out of 266\n",
      "237 out of 266\n",
      "238 out of 266\n",
      "239 out of 266\n",
      "240 out of 266\n",
      "241 out of 266\n",
      "242 out of 266\n",
      "243 out of 266\n",
      "244 out of 266\n",
      "245 out of 266\n",
      "246 out of 266\n",
      "247 out of 266\n",
      "248 out of 266\n",
      "249 out of 266\n",
      "250 out of 266\n",
      "251 out of 266\n",
      "252 out of 266\n",
      "253 out of 266\n",
      "254 out of 266\n",
      "255 out of 266\n",
      "256 out of 266\n",
      "257 out of 266\n",
      "258 out of 266\n",
      "259 out of 266\n",
      "260 out of 266\n",
      "261 out of 266\n",
      "262 out of 266\n",
      "263 out of 266\n",
      "264 out of 266\n",
      "265 out of 266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7289213638447378, 7980)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = 0\n",
    "n = 0\n",
    "\n",
    "for date_idx, val in enumerate(dates_test):\n",
    "    print(f'{date_idx} out of {len(dates_test)}')\n",
    "    # Create dataset with missed values\n",
    "    data_test_missed = data_test.copy()\n",
    "    data_test_missed[date_idx, :, :, missed_strike] = MISSED_VALUE\n",
    "    # Create normalized dataset with missed values\n",
    "    data_norm_test_missed = data_norm_test.copy()\n",
    "    data_norm_test_missed[date_idx, :, :, missed_strike] = MISSED_VALUE\n",
    "\n",
    "    # Complete the missed data in vol cube and check errors against real data\n",
    "    z_optimal = find_z_to_complete_vol_cube(vae=vae,\n",
    "                                        data=data_norm_test_missed[date_idx],\n",
    "                                        random_attempt_num=30, # number of attempts starting from different random z initial values\n",
    "                                        random_seed=0,\n",
    "                                        print_status=False\n",
    "                                        )\n",
    "    \n",
    "    predictions = normalizer.denormalize(vae.decoder.predict(np.array([z_optimal]), verbose=0))  # shape=(1,6,5,7)\n",
    "    \n",
    "    for i in range(predictions.shape[1]):\n",
    "        for j in range(predictions.shape[2]):\n",
    "            for k in range(predictions.shape[3]):\n",
    "                if uniq_strikes[k] in strikes:\n",
    "                    if data_test_missed[date_idx, i, j, k] != MISSED_VALUE:\n",
    "                        predictions[0, i, j, k] = data_test[date_idx, i, j, k]\n",
    "                    else:\n",
    "                        mse += (predictions[0, i, j, k] - data_test[date_idx, i, j, k])**2\n",
    "                        n += 1\n",
    "\n",
    "(mse / n) ** 0.5, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's select that all values except ATM vols will be missed for the date with largest vols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create dataset with missed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset data_norm_test_missed with missed data\n",
    "import numpy as np\n",
    "missed_strikes = [0, 1, 2, 4, 5, 6]  # 0 is ATM-100bp, 3 is ATM, 6 is ATM+100bp\n",
    "\n",
    "# Import what value is considered as a missed value\n",
    "from references.global_parameters import MISSED_VALUE\n",
    "\n",
    "from src.visualization.vol.find_z_to_complete_vol_cube import find_z_to_complete_vol_cube\n",
    "strikes = ['ATM-100bp', 'ATM-50bp', 'ATM', 'ATM+50bp', 'ATM+100bp']  # graphs only for these strikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate mse error over all test dates when we complete the dataset (takes 6 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 266\n",
      "1 out of 266\n",
      "2 out of 266\n",
      "3 out of 266\n",
      "4 out of 266\n",
      "5 out of 266\n",
      "6 out of 266\n",
      "7 out of 266\n",
      "8 out of 266\n",
      "9 out of 266\n",
      "10 out of 266\n",
      "11 out of 266\n",
      "12 out of 266\n",
      "13 out of 266\n",
      "14 out of 266\n",
      "15 out of 266\n",
      "16 out of 266\n",
      "17 out of 266\n",
      "18 out of 266\n",
      "19 out of 266\n",
      "20 out of 266\n",
      "21 out of 266\n",
      "22 out of 266\n",
      "23 out of 266\n",
      "24 out of 266\n",
      "25 out of 266\n",
      "26 out of 266\n",
      "27 out of 266\n",
      "28 out of 266\n",
      "29 out of 266\n",
      "30 out of 266\n",
      "31 out of 266\n",
      "32 out of 266\n",
      "33 out of 266\n",
      "34 out of 266\n",
      "35 out of 266\n",
      "36 out of 266\n",
      "37 out of 266\n",
      "38 out of 266\n",
      "39 out of 266\n",
      "40 out of 266\n",
      "41 out of 266\n",
      "42 out of 266\n",
      "43 out of 266\n",
      "44 out of 266\n",
      "45 out of 266\n",
      "46 out of 266\n",
      "47 out of 266\n",
      "48 out of 266\n",
      "49 out of 266\n",
      "50 out of 266\n",
      "51 out of 266\n",
      "52 out of 266\n",
      "53 out of 266\n",
      "54 out of 266\n",
      "55 out of 266\n",
      "56 out of 266\n",
      "57 out of 266\n",
      "58 out of 266\n",
      "59 out of 266\n",
      "60 out of 266\n",
      "61 out of 266\n",
      "62 out of 266\n",
      "63 out of 266\n",
      "64 out of 266\n",
      "65 out of 266\n",
      "66 out of 266\n",
      "67 out of 266\n",
      "68 out of 266\n",
      "69 out of 266\n",
      "70 out of 266\n",
      "71 out of 266\n",
      "72 out of 266\n",
      "73 out of 266\n",
      "74 out of 266\n",
      "75 out of 266\n",
      "76 out of 266\n",
      "77 out of 266\n",
      "78 out of 266\n",
      "79 out of 266\n",
      "80 out of 266\n",
      "81 out of 266\n",
      "82 out of 266\n",
      "83 out of 266\n",
      "84 out of 266\n",
      "85 out of 266\n",
      "86 out of 266\n",
      "87 out of 266\n",
      "88 out of 266\n",
      "89 out of 266\n",
      "90 out of 266\n",
      "91 out of 266\n",
      "92 out of 266\n",
      "93 out of 266\n",
      "94 out of 266\n",
      "95 out of 266\n",
      "96 out of 266\n",
      "97 out of 266\n",
      "98 out of 266\n",
      "99 out of 266\n",
      "100 out of 266\n",
      "101 out of 266\n",
      "102 out of 266\n",
      "103 out of 266\n",
      "104 out of 266\n",
      "105 out of 266\n",
      "106 out of 266\n",
      "107 out of 266\n",
      "108 out of 266\n",
      "109 out of 266\n",
      "110 out of 266\n",
      "111 out of 266\n",
      "112 out of 266\n",
      "113 out of 266\n",
      "114 out of 266\n",
      "115 out of 266\n",
      "116 out of 266\n",
      "117 out of 266\n",
      "118 out of 266\n",
      "119 out of 266\n",
      "120 out of 266\n",
      "121 out of 266\n",
      "122 out of 266\n",
      "123 out of 266\n",
      "124 out of 266\n",
      "125 out of 266\n",
      "126 out of 266\n",
      "127 out of 266\n",
      "128 out of 266\n",
      "129 out of 266\n",
      "130 out of 266\n",
      "131 out of 266\n",
      "132 out of 266\n",
      "133 out of 266\n",
      "134 out of 266\n",
      "135 out of 266\n",
      "136 out of 266\n",
      "137 out of 266\n",
      "138 out of 266\n",
      "139 out of 266\n",
      "140 out of 266\n",
      "141 out of 266\n",
      "142 out of 266\n",
      "143 out of 266\n",
      "144 out of 266\n",
      "145 out of 266\n",
      "146 out of 266\n",
      "147 out of 266\n",
      "148 out of 266\n",
      "149 out of 266\n",
      "150 out of 266\n",
      "151 out of 266\n",
      "152 out of 266\n",
      "153 out of 266\n",
      "154 out of 266\n",
      "155 out of 266\n",
      "156 out of 266\n",
      "157 out of 266\n",
      "158 out of 266\n",
      "159 out of 266\n",
      "160 out of 266\n",
      "161 out of 266\n",
      "162 out of 266\n",
      "163 out of 266\n",
      "164 out of 266\n",
      "165 out of 266\n",
      "166 out of 266\n",
      "167 out of 266\n",
      "168 out of 266\n",
      "169 out of 266\n",
      "170 out of 266\n",
      "171 out of 266\n",
      "172 out of 266\n",
      "173 out of 266\n",
      "174 out of 266\n",
      "175 out of 266\n",
      "176 out of 266\n",
      "177 out of 266\n",
      "178 out of 266\n",
      "179 out of 266\n",
      "180 out of 266\n",
      "181 out of 266\n",
      "182 out of 266\n",
      "183 out of 266\n",
      "184 out of 266\n",
      "185 out of 266\n",
      "186 out of 266\n",
      "187 out of 266\n",
      "188 out of 266\n",
      "189 out of 266\n",
      "190 out of 266\n",
      "191 out of 266\n",
      "192 out of 266\n",
      "193 out of 266\n",
      "194 out of 266\n",
      "195 out of 266\n",
      "196 out of 266\n",
      "197 out of 266\n",
      "198 out of 266\n",
      "199 out of 266\n",
      "200 out of 266\n",
      "201 out of 266\n",
      "202 out of 266\n",
      "203 out of 266\n",
      "204 out of 266\n",
      "205 out of 266\n",
      "206 out of 266\n",
      "207 out of 266\n",
      "208 out of 266\n",
      "209 out of 266\n",
      "210 out of 266\n",
      "211 out of 266\n",
      "212 out of 266\n",
      "213 out of 266\n",
      "214 out of 266\n",
      "215 out of 266\n",
      "216 out of 266\n",
      "217 out of 266\n",
      "218 out of 266\n",
      "219 out of 266\n",
      "220 out of 266\n",
      "221 out of 266\n",
      "222 out of 266\n",
      "223 out of 266\n",
      "224 out of 266\n",
      "225 out of 266\n",
      "226 out of 266\n",
      "227 out of 266\n",
      "228 out of 266\n",
      "229 out of 266\n",
      "230 out of 266\n",
      "231 out of 266\n",
      "232 out of 266\n",
      "233 out of 266\n",
      "234 out of 266\n",
      "235 out of 266\n",
      "236 out of 266\n",
      "237 out of 266\n",
      "238 out of 266\n",
      "239 out of 266\n",
      "240 out of 266\n",
      "241 out of 266\n",
      "242 out of 266\n",
      "243 out of 266\n",
      "244 out of 266\n",
      "245 out of 266\n",
      "246 out of 266\n",
      "247 out of 266\n",
      "248 out of 266\n",
      "249 out of 266\n",
      "250 out of 266\n",
      "251 out of 266\n",
      "252 out of 266\n",
      "253 out of 266\n",
      "254 out of 266\n",
      "255 out of 266\n",
      "256 out of 266\n",
      "257 out of 266\n",
      "258 out of 266\n",
      "259 out of 266\n",
      "260 out of 266\n",
      "261 out of 266\n",
      "262 out of 266\n",
      "263 out of 266\n",
      "264 out of 266\n",
      "265 out of 266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.1914714202282726, 31920)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = 0\n",
    "n = 0\n",
    "\n",
    "for date_idx, val in enumerate(dates_test):\n",
    "    print(f'{date_idx} out of {len(dates_test)}')\n",
    "    # Create dataset with missed values\n",
    "    data_test_missed = data_test.copy()\n",
    "    for missed_stk in missed_strikes:\n",
    "        data_test_missed[date_idx,:, :, missed_stk] = MISSED_VALUE\n",
    "\n",
    "    # Create normalized dataset with missed values\n",
    "    data_norm_test_missed = data_norm_test.copy()\n",
    "    for missed_stk in missed_strikes:\n",
    "        data_norm_test_missed[date_idx,:, :, missed_stk] = MISSED_VALUE\n",
    "\n",
    "    # Complete the missed data in vol cube and check errors against real data\n",
    "    z_optimal = find_z_to_complete_vol_cube(vae=vae,\n",
    "                                        data=data_norm_test_missed[date_idx],\n",
    "                                        random_attempt_num=30, # number of attempts starting from different random z initial values\n",
    "                                        random_seed=0,\n",
    "                                        print_status=False\n",
    "                                        )\n",
    "    \n",
    "    predictions = normalizer.denormalize(vae.decoder.predict(np.array([z_optimal]), verbose=0))  # shape=(1,6,5,7)\n",
    "    \n",
    "    for i in range(predictions.shape[1]):\n",
    "        for j in range(predictions.shape[2]):\n",
    "            for k in range(predictions.shape[3]):\n",
    "                if uniq_strikes[k] in strikes:\n",
    "                    if data_test_missed[date_idx, i, j, k] != MISSED_VALUE:\n",
    "                        predictions[0, i, j, k] = data_test[date_idx, i, j, k]\n",
    "                    else:\n",
    "                        mse += (predictions[0, i, j, k] - data_test[date_idx, i, j, k])**2\n",
    "                        n += 1\n",
    "\n",
    "(mse / n) ** 0.5, n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
